# ‚úÖ Meaning of **System Design**

**System Design** means:

> **Planning and structuring a software system** by deciding
> **how different components (frontend, backend, database, APIs, servers, etc.) will work together**.

---

### üîπ Simple words (easy to remember)

**System Design = Soch + Planning + Architecture**
---

# Types of System design

## 1Ô∏è‚É£ High-Level Design (HLD)

### üëâ What it focuses on:
- Overall **architecture**
- Major **components**
- How components **communicate**
- Technology choices

### üîπ Includes:
- Frontend
- Backend services
- Load balancer
- Database
- Cache
- Message queue
- CDN

## 2Ô∏è‚É£ Low-Level Design (LLD)

### üëâ What it focuses on:
- **Internal details**
- Classes & objects
- APIs
- DB tables
- Relationships
- Design patterns

### üîπ Includes:
- Class diagrams
- API contracts
- Database schema
- Method-level design

---

## 3Ô∏è‚É£ (Bonus) Detailed Design / Micro Design  
Some companies split LLD further:
- Error handling
- Validation
- Concurrency
- Transactions
- Edge cases

---

## Easy way to remember üß†
| Type | Think Like |
|----|----|
| HLD | **Architect** üèóÔ∏è |
| LLD | **Developer** üíª |

---

## üî∑ What is High-Level Design (HLD)?

**HLD** explains:

> **What components exist in the system and how they talk to each other**,
> without going into class-level or code-level details.

Think like a **software architect**, not a coder.

---

## üî∑ HLD ‚Äì Step-by-Step Approach (INTERVIEW GOLD ‚≠ê)

### 1Ô∏è‚É£ Clarify Requirements (ALWAYS FIRST)

Split into:

#### ‚úÖ Functional Requirements

What the system **must do**

* User can register/login
* User can place order
* User can search products

#### ‚úÖ Non-Functional Requirements

How well the system should work:

* Scalability (millions of users)
* High availability
* Low latency
* Security
* Consistency

üìå **Never skip this step in interviews**

---

### 2Ô∏è‚É£ Identify Major Components

Almost every scalable system has:

```
Client (Web / Mobile)
      ‚Üì
Load Balancer
      ‚Üì
API Servers
      ‚Üì
Cache (Redis)
      ‚Üì
Database
      ‚Üì
Message Queue
```

---

### 3Ô∏è‚É£ Request Flow (Explain Clearly)

Example: **User places an order**

1. User sends request from app
2. Load Balancer distributes traffic
3. API Server validates request
4. Cache checked first
5. DB updated
6. Event sent to queue (email, notification)

üí° Interviewers love **clear flow explanation**

---

### 4Ô∏è‚É£ Scalability Design (VERY IMPORTANT)

#### Horizontal Scaling

* Add more servers
* Stateless APIs

#### Vertical Scaling

* Bigger machine
* Limited scaling

üëâ **Preferred: Horizontal**

---

### 5Ô∏è‚É£ Database Design (HLD Level)

* SQL ‚Üí transactions (orders, payments)
* NoSQL ‚Üí large scale reads (products, logs)

#### Techniques:

* Read replicas
* Sharding
* Indexing

---

### 6Ô∏è‚É£ Caching Strategy

Why cache?

* Reduce DB load
* Faster response

Where cache?

* User sessions
* Product details
* Search results

Types:

* Read-through
* Write-through
* Write-behind

---

### 7Ô∏è‚É£ Load Balancer

Distributes traffic:

* Round Robin
* Least connections

Also:

* Health checks
* Failover

---

### 8Ô∏è‚É£ Message Queue (Async Processing)

Used for:

* Emails
* Notifications
* Payment processing
* Logging

Examples:

* Kafka
* RabbitMQ
* SQS

üí° Helps in **decoupling services**

---

### 9Ô∏è‚É£ Fault Tolerance & Reliability

* Retry mechanisms
* Circuit breakers
* Timeouts
* Replication
* Failover

---

### üî∑ Typical HLD Diagram (Text View)

```
Mobile/Web App
      |
   Load Balancer
      |
  API Gateway
      |
  Microservices
   |      |
 Cache   Queue
   |      |
 Database |
          |
     Notification Service
```

---

## 1Ô∏è‚É£ Read Replica

A **Read Replica** is a **copy of the main (primary) database** that is used **only for read operations**.

### Why it is used

* When **read traffic is very high**
* To reduce load on the **primary database**
* To improve **read performance**

### How it works

* All **write operations** (INSERT, UPDATE, DELETE) go to **Primary DB**
* **Read operations** (SELECT) are routed to **Read Replicas**

### Benefits

* Better performance
* High availability
* Easy horizontal scaling

### Drawback

* Data can be **slightly stale** (replication lag)

---

## 2Ô∏è‚É£ Sharding

**Sharding** means **splitting data across multiple databases** instead of keeping all data in one database.

Each shard contains **only a portion of data**.

### Why it is used

* When database size becomes very large
* When one database cannot handle traffic
* To scale **both read and write**

### How it works

Data is divided using a **shard key**, for example:

* User ID
* Order ID
* Region

```
Shard 1 ‚Üí Users 1‚Äì1M
Shard 2 ‚Üí Users 1M‚Äì2M
Shard 3 ‚Üí Users 2M‚Äì3M
```

### Benefits

* Massive scalability
* Better performance
* Distributed load

### Drawbacks

* Complex queries (joins across shards)
* Re-sharding is difficult
* More operational complexity

---

## 3Ô∏è‚É£ Indexing

**Indexing** is a data structure (like a **table of contents**) that helps the database **find data faster**.

### Why it is used

* To speed up **SELECT queries**
* To avoid full table scans

### How it works

Without index:

```
Search ‚Üí Scan every row ‚ùå
```

With index:

```
Search ‚Üí Direct lookup ‚úîÔ∏è
```

Example:

```sql
CREATE INDEX idx_email ON users(email);
```

### Benefits

* Faster query execution
* Improved read performance

### Drawbacks

* Slower write operations
* Extra storage needed

---

##  Types of Sharding

There are **4 main types of sharding** used in real systems.

---

### üîπ 1. Horizontal Sharding (Most Common ‚≠ê)

Rows are divided across multiple databases.

Each shard has the **same schema** but **different rows**.

#### Example

```
Shard 1 ‚Üí User IDs 1 ‚Äì 1,000,000
Shard 2 ‚Üí User IDs 1,000,001 ‚Äì 2,000,000
Shard 3 ‚Üí User IDs 2,000,001 ‚Äì 3,000,000
```

#### Used when

* Large number of users
* High read & write traffic

#### Pros

* Scales very well
* Most practical approach

#### Cons

* Cross-shard queries are hard

---

### üîπ 2. Vertical Sharding

Columns are split across different databases.

#### Example

```
User_Core_DB  ‚Üí userId, name, email
User_Extra_DB ‚Üí address, preferences, logs
```

#### Used when

* Some columns are accessed frequently
* Some data is rarely used

#### Pros

* Smaller tables
* Faster queries for core data

#### Cons

* Multiple DB calls needed
* Joins across databases

---

### üîπ 3. Hash-Based Sharding

A **hash function** decides which shard the data goes to.

#### Example

```
shardId = hash(userId) % number_of_shards
```

User with ID 101 ‚Üí hash ‚Üí Shard 2

#### Pros

* Very even data distribution
* No hot shards

#### Cons

* Adding/removing shards is hard
* Re-hashing needed

---

### üîπ 4. Range-Based Sharding

Data is divided based on **value ranges**.

#### Example

```
Shard 1 ‚Üí Orders from Jan‚ÄìMar
Shard 2 ‚Üí Orders from Apr‚ÄìJun
Shard 3 ‚Üí Orders from Jul‚ÄìSep
```

#### Pros

* Simple
* Easy range queries

#### Cons

* Uneven load (hot shards)

---

## How Sharding Actually Works (Step-by-Step)

Let‚Äôs take **User Service** example.

---

### Step 1: Choose Shard Key

A field used to decide shard.
Examples:

* userId (best)
* orderId
* region

üëâ Shard key must be:

* Present in most queries
* Evenly distributed

---

### Step 2: Shard Router / Lookup Layer

A **routing layer** decides Which shard should handle this request based on shard techniques.

```
Request ‚Üí Shard Router ‚Üí Correct DB Shard
```

---


Great üëç
This is a **must-know HLD topic**. I‚Äôll explain **Scaling**, **its types**, and **when scaling is required** ‚Äî **clearly, practically, and interview-ready**.

---

## üî∑ What is Scaling?

**Scaling** means:

> **Increasing a system‚Äôs capacity to handle more load**
> (users, requests, data, traffic) **without breaking performance**.

In simple terms:
‚û°Ô∏è *More users + more data + more requests = need scaling*

---

## üî∑ Why Scaling is Needed?

Scaling is required when:

* System becomes **slow**
* Requests start **failing**
* CPU / memory / DB is overloaded
* Traffic grows beyond current capacity

---

## üî∑ Types of Scaling (Very Important ‚≠ê)

There are **TWO main types of scaling**.

---

## 1Ô∏è‚É£ Vertical Scaling (Scale Up)

### Meaning

Increase the **power of a single machine**.

Examples:

* 8GB RAM ‚Üí 32GB RAM
* 4 CPU ‚Üí 16 CPU
* Bigger DB instance

### Diagram

```
Before:  Small Server
After:   Bigger Server
```

### Pros

* Simple to implement
* No code changes
* Works well initially

### Cons

* Hardware limit
* Expensive
* Single point of failure

### Used When

* Early stage system
* Low to medium traffic
* Quick fix

---

## 2Ô∏è‚É£ Horizontal Scaling (Scale Out) ‚≠ê (Preferred)

### Meaning

Add **more machines/servers** instead of making one bigger.

Examples:

* 1 server ‚Üí 10 servers
* Multiple DB shards
* Multiple API instances

### Diagram

```
User
 ‚Üì
Load Balancer
 ‚Üì
Server 1
Server 2
Server 3
```

### Pros

* High scalability
* Fault tolerant
* No single point of failure

### Cons

* More complex
* Requires stateless services
* Needs load balancing

### Used When

* High traffic
* Millions of users
* Enterprise systems

---

## üî∑ Scaling Types by Layer (INTERVIEW BONUS)

### üîπ 1. Application Scaling

* Add more API servers
* Stateless services
* Load balancer

### üîπ 2. Database Scaling

* Read replicas
* Sharding
* Partitioning

### üîπ 3. Cache Scaling

* Redis cluster
* Distributed cache

### üîπ 4. Storage Scaling

* Distributed storage (S3, HDFS)

---

## üî∑ When EXACTLY to Scale? (VERY IMPORTANT)

### Scale when you see:

1Ô∏è‚É£ High latency
2Ô∏è‚É£ High CPU / memory usage
3Ô∏è‚É£ DB connections exhausted
4Ô∏è‚É£ Timeouts / errors
5Ô∏è‚É£ Traffic growth trends
6Ô∏è‚É£ SLA violations

---

## üî∑ Real Example (Easy to Remember)

### Problem:

E-commerce site slow during sale.

### Solution:

1. Cache product data
2. Add read replicas
3. Scale API servers horizontally
4. Shard orders DB if needed

---

## ‚úÖ What is a **Stateless Service**?

A **stateless service** is a service that **does NOT store any client/session data in its own memory** between requests.

üëâ **Each request is independent** and contains **all the information needed** to process it.

> A stateless service does not remember previous requests; every request is handled as a new one.

---

## üîπ Example (Stateless API)

```http
GET /orders
Headers:
Authorization: Bearer <JWT_TOKEN>
```

* The server does **not remember the user**
* Authentication info comes with **every request**
* Any server can handle the request. ( Each server does NOT have its own database,
but YES ‚úÖ each server has the same application (API) code.)

---

## üîπ Why Stateless Services are Important?

Because they allow **horizontal scaling**.

‚û°Ô∏è Any server can handle any request
‚û°Ô∏è No dependency on previous requests

---

## üîπ How Statelessness is Achieved

### 1Ô∏è‚É£ No Session Stored in Server Memory ‚ùå

Bad:

```text
Server stores user session in RAM
```

### 2Ô∏è‚É£ Use Tokens (JWT / OAuth) ‚úÖ

* Client sends token every time
* Server validates token

### 3Ô∏è‚É£ External State Storage ‚úÖ

If state is needed, store it in:

* Redis
* Database
* Distributed cache

---

## üîπ Stateful Service Example

* Shopping cart stored in server memory
* User must always hit **same server**
* Requires **sticky sessions**

---

## üîπ Stateless Service Example

* REST APIs
* Microservices
* Authentication using JWT

---

## Load Balancer - 

A load balancer continuously monitors backend health and deterministically routes each incoming request to a healthy server using a configured algorithm.

Load Balancer Machine Actually Has Two ‚Äúsides‚Äù of networking

Front side (Client-facing):

Public IP, Receives internet traffic, Terminates TCP / TLS (HTTPS)

Back side (Server-facing):

Private IPs of backend servers, Talks to them inside VPC / data center

### But Isn‚Äôt LB a Single Point of Failure?

In production, LB itself is replicated.

--------------

## What is a Message Queue?

A Message Queue (MQ) is:

A buffer that stores messages so that one service can send work to another service asynchronously.

In simple words:
‚û°Ô∏è ‚ÄúDo this task later, not now.‚Äù

Without MQ:

Services call each other synchronously. If one service is slow or down ‚Üí whole flow breaks. User waits longer.

With MQ: Sender and receiver are decoupled, System becomes resilient & scalable

**Think of Kafka as:**

A set of servers that store ordered files (logs) and allow many systems to read those files independently.
Producers append events and consumer groups read them independently.

-----------------------------

## üîÅ What Is the Saga Pattern?

The Saga pattern manages distributed transactions by executing a sequence of local transactions and using compensating actions to handle failures, avoiding the need for distributed locks and enabling scalability in microservices architectures.

---

## ‚ùå Why Traditional Transactions Don‚Äôt Work

### Problem with 2-Phase Commit (2PC):

* Locks multiple services
* Poor performance
* Not scalable
* Single point of failure

üëâ **Modern microservices avoid 2PC**

---

## ‚úÖ Why Saga Pattern Works

* No global lock
* Each service controls its own DB
* Failure is handled by **compensation**, not rollback
* Asynchronous & scalable

---

## üß© Core Concepts of Saga

1Ô∏è‚É£ Local transaction
2Ô∏è‚É£ Event/message
3Ô∏è‚É£ Next step
4Ô∏è‚É£ Compensating transaction

---

## üì¶ Example: Food Delivery Order Saga

### Services Involved:

* Order Service
* Payment Service
* Delivery Service

---

### Step-by-Step Saga Flow

#### 1Ô∏è‚É£ Order Created

* Order Service saves order
* Status = `PENDING_PAYMENT`
* Emits event

```
ORDER_CREATED
```

---

#### 2Ô∏è‚É£ Payment Processed

* Payment Service processes payment

**Success**

```
PAYMENT_SUCCESS
```

**Failure**

```
PAYMENT_FAILED
```

---

#### 3Ô∏è‚É£ Delivery Assigned

* Delivery Service assigns rider

**Failure here?**
üëâ Trigger **refund** (compensation)

---

## üîÑ Compensating Transactions (Key Idea)

| Step            | Action       | Compensation   |
| --------------- | ------------ | -------------- |
| Create Order    | Save order   | Cancel order   |
| Process Payment | Deduct money | Refund         |
| Assign Delivery | Assign rider | Unassign rider |

‚úî No rollback
‚úî Forward recovery

---

## üèóÔ∏è Two Types of Saga Patterns

## 1Ô∏è‚É£ Choreography-Based Saga

### How It Works:

* No central coordinator
* Services react to events

```
Order ‚Üí Payment ‚Üí Delivery
```

### Pros:

* Simple
* Loosely coupled

### Cons:

* Hard to track flow
* Debugging is difficult

---

## 2Ô∏è‚É£ Orchestration-Based Saga ‚≠ê‚≠ê‚≠ê

### How It Works:

* Central **Saga Orchestrator**
* Controls flow

```
Orchestrator ‚Üí Payment ‚Üí Delivery
```

---

## ‚ùì How Do You Ensure No Duplicate Orders Are Created?

Duplicate orders usually happen because of:

* Network retries
* Client resubmitting request
* Timeout but backend already processed
* User clicking ‚ÄúPlace Order‚Äù multiple times

So the system must be **idempotent**.

---

## 1Ô∏è‚É£ Core Concept: Idempotency ‚≠ê‚≠ê‚≠ê

> An operation is idempotent if **executing it multiple times gives the same result**.

In simple words:
‚û°Ô∏è Same request ‚Üí **only one order created**

---

## 2Ô∏è‚É£ Idempotency Key (Main Solution)

### How It Works:

* Client generates a **unique idempotency key**
* Sends it with order request

```
POST /orders
Headers:
Idempotency-Key: abc123
```

---

### Backend Logic:

1. Check if this key already exists
2. If YES ‚Üí return existing order
3. If NO ‚Üí create new order

---

## 3Ô∏è‚É£ Database-Level Protection (VERY IMPORTANT)

Even if application fails, DB should protect.

### Unique Constraints

```sql
UNIQUE (idempotency_key)
or
UNIQUE (user_id, cart_hash)
```

‚úî Last line of defense
‚úî Prevents race conditions

---